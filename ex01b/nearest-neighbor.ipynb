{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 1b\n",
    "#### Tutor: Jeremias Traub\n",
    "#### Kevin Heibel, Max Heise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1 Nearest Neighbor Classification on Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.1 Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
      "float64\n",
      "(1797, 8, 8)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "print (digits.keys())\n",
    "\n",
    "data = digits [\"data\"]\n",
    "images = digits [\"images\"]\n",
    "target = digits [\"target\"]\n",
    "target_names = digits [\"target_names\"]\n",
    "print(data.dtype)\n",
    "print(images.shape)\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-> images have a size of 8x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = images[3]\n",
    "assert 2 == len(img.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.gray()\n",
    "plt.imshow(img , interpolation =\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight:bold\">\n",
    "Did not plot with bicubic interpolation.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = data\n",
    "y_all = target\n",
    "\n",
    "X_train , X_test , Y_train , Y_test =\\\n",
    "    model_selection.train_test_split( digits.data, digits.target,\n",
    "          test_size = 0.4, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.2 Distance function computation using loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "computes the Euclidean distance between all instances in the training and test set (in the feature space)\n",
    "input: N × D training matrices with D pixels per image and N instances in the training set\n",
    "       M × D test matrices with D pixels per image and M instances in the test set\n",
    "output: N × M distance matrix.\n",
    "'''\n",
    "\n",
    "def dist_loop(training, test):\n",
    "    N = training.shape[0]\n",
    "    M = test.shape[0]\n",
    "    distance_matrix = np.zeros((N,M))\n",
    "    \n",
    "    for i, instance1 in enumerate(training):\n",
    "        for j, instance2 in enumerate(test):\n",
    "            distance = np.sqrt(np.sum(np.square(np.subtract(instance1, instance2))))\n",
    "            distance_matrix[i][j] = distance\n",
    "    \n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight:bold\">\n",
    "Looks good. The doc strings are supposed to go below the function signature. This way they can be displayed with the help function.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.3 Distance function computation using vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "distance function which relies on vectorization and does not use loops\n",
    "input: N × D training matrices with D pixels per image and N instances in the training set\n",
    "       M × D test matrices with D pixels per image and M instances in the test set\n",
    "output: N × M distance matrix.\n",
    "'''\n",
    "\n",
    "def dist_vec(training, test):\n",
    "    N = training.shape[0]\n",
    "    M = test.shape[0]\n",
    "\n",
    "    training_squared = (training*training).sum(axis=1).reshape((N,1)) * np.ones(shape=(1,M))\n",
    "    test_squared = (test*test).sum(axis=1)*np.ones(shape=(N,1))\n",
    "    distance_matrix =  np.sqrt(training_squared + test_squared - 2 * training.dot(test.T))\n",
    "\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight:bold\">\n",
    "Use built in numpy function for square.\n",
    "Otherwise the function does the right thing.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print((dist_loop(X_train, X_test) ==  dist_vec(X_train, X_test)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop function:\n",
      "voctorized function:\n"
     ]
    }
   ],
   "source": [
    "# measure time of loop function\n",
    "print(\"loop function:\")\n",
    "#%timeit dist_loop(X_train, X_test)\n",
    "\n",
    "print(\"voctorized function:\")\n",
    "#%timeit dist_vec(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.4 Implement the k-nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "k-nearest neighbor classifier\n",
    "input: N × D training matrices with D pixels per image and N instances in the training set\n",
    "       N corresponding true labels\n",
    "       M × D test matrices with D pixels per image and M instances in the test set\n",
    "       k as the number of neighbors to look at\n",
    "output: N predicted Y labels\n",
    "'''\n",
    "\n",
    "def k_nearest_neighbor(X_test, X_train, Y_train, k):\n",
    "    distance_matrix = dist_vec(X_train, X_test)\n",
    "    Y_test = np.zeros(X_test.shape[0])\n",
    "    for i, instance in enumerate(X_test):\n",
    "        distances = distance_matrix[:, i:i+1]\n",
    "        smallest_distance = np.array(distances[:k])\n",
    "        smallest_distance_index = np.arange(k)\n",
    "        for j, distance in enumerate(distances):\n",
    "            if distance <= np.amax(smallest_distance):\n",
    "                smallest_distance[smallest_distance.argmax()] = distance\n",
    "                smallest_distance_index[smallest_distance.argmax()] = j\n",
    "        Y_nearest = Y_train[smallest_distance_index]\n",
    "        Y_counts = np.bincount(Y_nearest)\n",
    "        Y_predict = np.argmax(Y_counts)\n",
    "        Y_test[i] = Y_predict\n",
    "    return Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight:bold\">\n",
    "This solution is more complex than it needs to. It would be more readable and faster if it was vectorized. Your error rates also indicate that it is not correct. We are not sure about it but we suspect the error to be in the inner loop. It can entirely be replaced by sorting the distances (and get the indicies using argsort).\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def error_test(Y_True, Y_Estimate):\n",
    "    y_is_false = 0\n",
    "    for i in range(Y_True.shape[0]):\n",
    "        if (Y_True[i] != Y_Estimate[i]):\n",
    "            y_is_false += 1\n",
    "    return y_is_false / Y_True.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error for k = 1\n",
      "0.013888888888888888\n",
      "error for k = 3\n",
      "0.027777777777777776\n",
      "error for k = 5\n",
      "0.041666666666666664\n",
      "error for k = 9\n",
      "0.013888888888888888\n",
      "error for k = 17\n",
      "0.020833333333333332\n",
      "error for k = 33\n",
      "0.027777777777777776\n"
     ]
    }
   ],
   "source": [
    "#select all instances and labels of 3 and 9\n",
    "X_train_restricted = X_train[(Y_train == 3) | (Y_train == 9)]\n",
    "Y_train_restricted = Y_train[(Y_train == 3) | (Y_train == 9)]\n",
    "\n",
    "X_test_restricted = X_test[(Y_test == 3) | (Y_test == 9)]\n",
    "Y_test_restricted = Y_test[(Y_test == 3) | (Y_test == 9)]\n",
    "\n",
    "for k in [1,3,5,9,17,33]:\n",
    "    Y_test_predicted = k_nearest_neighbor(X_test_restricted, X_train_restricted, Y_train_restricted, k)\n",
    "    print(\"error for k = \" + str(k))\n",
    "    print(error_test(Y_test_restricted, Y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight:bold\">\n",
    "The error behaves opposite to what we got. It should be lowest at k=5 not highest\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We couldn't see a specific trend in our calculations regarding the dependency of k, generally the error rate is extremely low. k=5 delivers the highest error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2 Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "randomly split the given data and labels into L folds (parts of roughly equal size)\n",
    "input: N × D data matrices with D pixels per image and N instances in the data set\n",
    "       N corresponding Y_labels\n",
    "       L as the size of folds\n",
    "output: L × S × D data matrices with D pixels per image and S instances per fold and L folds\n",
    "        L × S data matrices with S labels per fold and L folds\n",
    "'''\n",
    "\n",
    "def split_folds(data, target, L):\n",
    "    indices = np.arange(data.shape[0])\n",
    "    indices = np.random.permutation(indices)\n",
    "    data_permutated = np.zeros(data.shape)\n",
    "    target_permutated = np.zeros(target.shape)\n",
    "    for i,index in enumerate(indices):\n",
    "        data_permutated[i] = data[index]\n",
    "        target_permutated[i] = target[index]\n",
    "    X_split = np.array_split(data_permutated, L)\n",
    "    Y_split = np.array_split(target_permutated, L)\n",
    "\n",
    "    # faster way to index data and target\n",
    "    #X_split = np.array_split(data[indices], L) \n",
    "    #Y_split = np.array_split(target[indices], L)\n",
    "    return X_split, Y_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight:bold\">\n",
    "This is correct but you are doing more work than you need to. data_permutated = data[indices] does the exact same thing as the loop.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007579306704642116\n",
      "0.013913718187461201\n"
     ]
    }
   ],
   "source": [
    "L = 10\n",
    "X_folds, Y_folds = split_folds(data, target, L)\n",
    "\n",
    "k = 1\n",
    "errors = np.zeros((L))\n",
    "for i in range(L):\n",
    "    X = np.zeros((data.shape[0] - X_folds[i].shape[0], 64))\n",
    "    Y = np.zeros((target.shape[0] - Y_folds[i].shape[0]),dtype = np.dtype('int64'))\n",
    "    ind1 = 0\n",
    "    ind2 = 0\n",
    "    for j,fold in enumerate(X_folds):\n",
    "        if (j != i):\n",
    "            for instance in fold:\n",
    "                X[ind1] = instance\n",
    "                ind1 += 1\n",
    "    for j,fold in enumerate(Y_folds):\n",
    "        if (j != i):\n",
    "            for instance in fold:\n",
    "                Y[ind2] = int(instance)\n",
    "                ind2 += 1\n",
    "    errors[i] = (error_test(Y_folds[i],(k_nearest_neighbor(X_folds[i], X, Y, k))))\n",
    "    \n",
    "print(errors.std())\n",
    "print(errors.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight:bold\">\n",
    "A more elegant solution for using all but one fold in the training data is to use np.concatenate and list splicing.\n",
    "\n",
    "Also the comparison with scikit-learn is missing.\n",
    "\n",
    "Also you'r error rate is suspiciously good for k = 1.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Sadly we didn't have the time to test different L and k values."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec7934806f8124376a90f0712981b6243830dfa2de1727f9a0d6b81d02b24f67"
  },
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
